{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bda3d58a",
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "papermill": {
     "duration": 0.005747,
     "end_time": "2023-10-04T20:06:19.252361",
     "exception": false,
     "start_time": "2023-10-04T20:06:19.246614",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Homework:\n",
    "\n",
    "https://www.kaggle.com/lakshmi25npathi/imdb-dataset-of-50k-movie-reviews\n",
    "\n",
    "Класифікація на позитивні та негативні відгуки\n",
    "\n",
    "Використати spaCy (або інші моделі, методи)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ccc9b55",
   "metadata": {
    "papermill": {
     "duration": 0.00512,
     "end_time": "2023-10-04T20:06:19.262869",
     "exception": false,
     "start_time": "2023-10-04T20:06:19.257749",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Information about dataset\n",
    "\n",
    "\"IMDB dataset having 50K movie reviews for natural language processing or Text analytics. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training and 25,000 for testing. So, predict the number of positive and negative reviews using either classification or deep learning algorithms. For more dataset information, please go through the following link, http://ai.stanford.edu/~amaas/data/sentiment/ \""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db9c96c6",
   "metadata": {
    "papermill": {
     "duration": 0.004969,
     "end_time": "2023-10-04T20:06:19.273127",
     "exception": false,
     "start_time": "2023-10-04T20:06:19.268158",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Results from different notebooks:\n",
    "\n",
    "- GRU Model:  [0.49783108]\n",
    "- LSTM Model:  [0.49836373]\n",
    "- GAP Model:  [0.9808547]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc35d1f8",
   "metadata": {
    "papermill": {
     "duration": 0.004874,
     "end_time": "2023-10-04T20:06:19.283291",
     "exception": false,
     "start_time": "2023-10-04T20:06:19.278417",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Resource:\n",
    "- https://www.kaggle.com/code/meryemtetik/moviereviews-rnn-lstm-gru\n",
    "- https://www.kaggle.com/code/lovinggirls/text-preprocessing-nlp-pipeline-by-piyush-kumar\n",
    "- https://www.kaggle.com/code/marekm4/movie-reviews-simple-nlp-library\n",
    "- https://www.kaggle.com/code/martandsay/movie-review-sentiment-analysis-nlp\n",
    "- https://www.kaggle.com/code/ibrahimo/imdb-reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "69fdd32b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:06:19.296290Z",
     "iopub.status.busy": "2023-10-04T20:06:19.295052Z",
     "iopub.status.idle": "2023-10-04T20:06:31.896560Z",
     "shell.execute_reply": "2023-10-04T20:06:31.895246Z"
    },
    "papermill": {
     "duration": 12.611995,
     "end_time": "2023-10-04T20:06:31.900363",
     "exception": false,
     "start_time": "2023-10-04T20:06:19.288368",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import os    \n",
    "        \n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import string\n",
    "import tensorflow as tf\n",
    "\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "from tensorflow.keras import layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import GRU, LSTM, GlobalAveragePooling1D, Dense, TextVectorization, Input, Embedding, Flatten, Dropout, BatchNormalization\n",
    "from keras.callbacks import EarlyStopping\n",
    "from keras.optimizers import Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "af8e7194",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:06:31.920510Z",
     "iopub.status.busy": "2023-10-04T20:06:31.918906Z",
     "iopub.status.idle": "2023-10-04T20:06:44.512355Z",
     "shell.execute_reply": "2023-10-04T20:06:44.510591Z"
    },
    "papermill": {
     "duration": 12.604214,
     "end_time": "2023-10-04T20:06:44.514912",
     "exception": false,
     "start_time": "2023-10-04T20:06:31.910698",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\r\n",
      "Requirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\r\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\r\n",
      "Requirement already satisfied: numpy>=1.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (1.23.5)\r\n",
      "Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\r\n",
      "Requirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\r\n",
      "Requirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\r\n",
      "Requirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\r\n",
      "Requirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\r\n",
      "Requirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\r\n",
      "Requirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\r\n",
      "Requirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\r\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\r\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\r\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\r\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\r\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\r\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\r\n",
      "Note: you may need to restart the kernel to use updated packages.\n",
      "[nltk_data] Downloading package stopwords to /usr/share/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /usr/share/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "%pip install transformers\n",
    "\n",
    "import nltk\n",
    "from string import punctuation\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "\n",
    "stop_words = nltk.corpus.stopwords.words('english') + list(punctuation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fd4b1cd8",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:06:44.528756Z",
     "iopub.status.busy": "2023-10-04T20:06:44.528368Z",
     "iopub.status.idle": "2023-10-04T20:06:46.319394Z",
     "shell.execute_reply": "2023-10-04T20:06:46.318253Z"
    },
    "papermill": {
     "duration": 1.800908,
     "end_time": "2023-10-04T20:06:46.321820",
     "exception": false,
     "start_time": "2023-10-04T20:06:44.520912",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>positive</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review sentiment\n",
       "0  One of the other reviewers has mentioned that ...  positive\n",
       "1  A wonderful little production. <br /><br />The...  positive\n",
       "2  I thought this was a wonderful way to spend ti...  positive\n",
       "3  Basically there's a family where a little boy ...  negative\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...  positive"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('/kaggle/input/imdb-dataset-of-50k-movie-reviews/IMDB Dataset.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6f442d5",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:06:46.335147Z",
     "iopub.status.busy": "2023-10-04T20:06:46.334738Z",
     "iopub.status.idle": "2023-10-04T20:06:46.374008Z",
     "shell.execute_reply": "2023-10-04T20:06:46.372833Z"
    },
    "papermill": {
     "duration": 0.048388,
     "end_time": "2023-10-04T20:06:46.376069",
     "exception": false,
     "start_time": "2023-10-04T20:06:46.327681",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 50000 entries, 0 to 49999\n",
      "Data columns (total 2 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   review     50000 non-null  object\n",
      " 1   sentiment  50000 non-null  object\n",
      "dtypes: object(2)\n",
      "memory usage: 781.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "25f57f01",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:06:46.389753Z",
     "iopub.status.busy": "2023-10-04T20:06:46.388755Z",
     "iopub.status.idle": "2023-10-04T20:06:46.400896Z",
     "shell.execute_reply": "2023-10-04T20:06:46.399773Z"
    },
    "papermill": {
     "duration": 0.021383,
     "end_time": "2023-10-04T20:06:46.403208",
     "exception": false,
     "start_time": "2023-10-04T20:06:46.381825",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sentiment\n",
       "positive    25000\n",
       "negative    25000\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.sentiment.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15b071e2",
   "metadata": {
    "papermill": {
     "duration": 0.005763,
     "end_time": "2023-10-04T20:06:46.414991",
     "exception": false,
     "start_time": "2023-10-04T20:06:46.409228",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Dataset pre-processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "686451ca",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:06:46.428445Z",
     "iopub.status.busy": "2023-10-04T20:06:46.428100Z",
     "iopub.status.idle": "2023-10-04T20:06:46.445144Z",
     "shell.execute_reply": "2023-10-04T20:06:46.443878Z"
    },
    "papermill": {
     "duration": 0.026172,
     "end_time": "2023-10-04T20:06:46.447151",
     "exception": false,
     "start_time": "2023-10-04T20:06:46.420979",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>One of the other reviewers has mentioned that ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A wonderful little production. &lt;br /&gt;&lt;br /&gt;The...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I thought this was a wonderful way to spend ti...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Basically there's a family where a little boy ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Petter Mattei's \"Love in the Time of Money\" is...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  One of the other reviewers has mentioned that ...          1\n",
       "1  A wonderful little production. <br /><br />The...          1\n",
       "2  I thought this was a wonderful way to spend ti...          1\n",
       "3  Basically there's a family where a little boy ...          0\n",
       "4  Petter Mattei's \"Love in the Time of Money\" is...          1"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# coding target \n",
    "df['sentiment'] = df['sentiment'].map({'positive': 1,'negative' :0 })\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a24c0d47",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:06:46.461426Z",
     "iopub.status.busy": "2023-10-04T20:06:46.460407Z",
     "iopub.status.idle": "2023-10-04T20:06:56.657638Z",
     "shell.execute_reply": "2023-10-04T20:06:56.656287Z"
    },
    "papermill": {
     "duration": 10.207211,
     "end_time": "2023-10-04T20:06:56.660405",
     "exception": false,
     "start_time": "2023-10-04T20:06:46.453194",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting ttictoc\r\n",
      "  Downloading ttictoc-0.5.6-py3-none-any.whl (5.7 kB)\r\n",
      "Installing collected packages: ttictoc\r\n",
      "Successfully installed ttictoc-0.5.6\r\n"
     ]
    }
   ],
   "source": [
    "!pip install ttictoc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "29d91a62",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:06:56.676510Z",
     "iopub.status.busy": "2023-10-04T20:06:56.676070Z",
     "iopub.status.idle": "2023-10-04T20:45:12.264088Z",
     "shell.execute_reply": "2023-10-04T20:45:12.262898Z"
    },
    "papermill": {
     "duration": 2295.604847,
     "end_time": "2023-10-04T20:45:12.272113",
     "exception": false,
     "start_time": "2023-10-04T20:06:56.667266",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pre-processing time:  2285.762749088\n",
      "<bound method NDFrame.head of                                                   review  sentiment\n",
      "0      one of the other reviewer have mention that af...          1\n",
      "1      a wonderful little production < br /><br />the...          1\n",
      "2      I think this be a wonderful way to spend time ...          1\n",
      "3      basically there be a family where a little boy...          0\n",
      "4      petter Mattei 's love in the Time of money be ...          1\n",
      "...                                                  ...        ...\n",
      "49995  I think this movie do a down right good job it...          1\n",
      "49996  bad plot bad dialogue bad act idiotic directin...          0\n",
      "49997  I be a Catholic teach in parochial elementary ...          0\n",
      "49998  I be go to have to disagree with the previous ...          0\n",
      "49999  no one expect the Star Trek movie to be high a...          0\n",
      "\n",
      "[50000 rows x 2 columns]>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "from nltk import word_tokenize\n",
    "from ttictoc import tic,toc\n",
    "from IPython.display import clear_output\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\") # Loading english large corpus\n",
    "tic()\n",
    "\n",
    "def preprocesing_text_v1(text : str):\n",
    "    try:\n",
    "        text = text.lower()\n",
    "        text = re.sub(r\"@[A-Za-z0-9]+\", ' ', text)\n",
    "        text = re.sub(r\"<.*?>\", ' ', text) # Removing HTML tags\n",
    "        text = re.sub(r\"https?://\\S+\", ' ', text) # Removing urls\n",
    "        text = re.sub(r\"https?://[A-Za-z0-9./]+\", ' ', text)\n",
    "        text = re.sub(r\"[^a-zA-z.!?'0-9]\", ' ', text)\n",
    "        text = re.sub('\\t', ' ',  text)\n",
    "        text = re.sub(r\" +\", ' ', text)\n",
    "        text = text.strip(' ')\n",
    "        text = ' '.join([x for x in word_tokenize(text) if x not in stop_words])\n",
    "    except Exception as e :\n",
    "        print(e)\n",
    "    finally:\n",
    "        return text\n",
    "    \n",
    "# Spacy\n",
    "def preprocesing_text_v2(text):\n",
    "    doc = nlp(text)\n",
    "    preprocessed_text = [token.lemma_ for token in doc if not token.is_punct and \n",
    "                         token.text != ' ' and token.text != '\\n' and token.text != '<br />' \n",
    "                         and token.text != '<br/>']\n",
    "    return \" \".join(preprocessed_text)\n",
    "\n",
    "\n",
    "df['review'] = df['review'].apply(preprocesing_text_v2)\n",
    "\n",
    "clear_output(wait=True)\n",
    "tc=toc()\n",
    "print('Pre-processing time: ',tc)\n",
    "print(df.head)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9282dc84",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:45:12.288405Z",
     "iopub.status.busy": "2023-10-04T20:45:12.287546Z",
     "iopub.status.idle": "2023-10-04T20:45:13.054872Z",
     "shell.execute_reply": "2023-10-04T20:45:13.053162Z"
    },
    "papermill": {
     "duration": 0.77825,
     "end_time": "2023-10-04T20:45:13.056897",
     "exception": true,
     "start_time": "2023-10-04T20:45:12.278647",
     "status": "failed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['I', 'am', 'going', 'to', 'visit', 'you', 'this', 'night', '!']\n",
      "['I', 'have', 'Ph.D', 'in', 'A.I', '.']\n",
      "['I', 'am', 'here', 'to', 'help', '.', 'Mail', 'me', 'at', 'makelove', '@', 'gmail.com']\n",
      "['A', '2hr', 'ride', 'cost', '$', '10']\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'doc4' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 18\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;28mprint\u001b[39m(word_tokenize(sent4))\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m######################################################\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m token \u001b[38;5;129;01min\u001b[39;00m \u001b[43mdoc4\u001b[49m:\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(token)\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m######################################################\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;66;03m# spacy\u001b[39;00m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'doc4' is not defined"
     ]
    }
   ],
   "source": [
    "# Here presented examples of the tools for working with text \n",
    "######################################################\n",
    "# Tokenization\n",
    "# NLTK\n",
    "from nltk.tokenize import word_tokenize, sent_tokenize\n",
    "\n",
    "sent1 = \"I am going to visit you this night!\"\n",
    "sent2 = \"I have Ph.D in A.I.\"\n",
    "sent3 = \"I am here to help. Mail me at makelove@gmail.com\"\n",
    "sent4 = \"A 2hr ride cost $10\"\n",
    "\n",
    "print(word_tokenize(sent1))\n",
    "print(word_tokenize(sent2))\n",
    "print(word_tokenize(sent3))\n",
    "print(word_tokenize(sent4))\n",
    "\n",
    "######################################################\n",
    "for token in doc4:\n",
    "    print(token)\n",
    "\n",
    "######################################################\n",
    "# spacy\n",
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "\n",
    "doc1 = nlp(sent1)\n",
    "doc2 = nlp(sent2)\n",
    "doc3 = nlp(sent3)\n",
    "doc4 = nlp(sent4)\n",
    "\n",
    "######################################################\n",
    "for token in doc1:\n",
    "    print(token)\n",
    "\n",
    "# Stemming    \n",
    "######################################################\n",
    "#test = 'walk walks walking walked'\n",
    "#stem_words(test)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "550c9b06",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Train-Test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b47333bd",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:57:23.922192Z",
     "iopub.status.busy": "2023-10-04T19:57:23.921792Z",
     "iopub.status.idle": "2023-10-04T19:57:34.702943Z",
     "shell.execute_reply": "2023-10-04T19:57:34.701370Z",
     "shell.execute_reply.started": "2023-10-04T19:57:23.922162Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "!pip install simple_nlp_library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ace7d2c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T19:59:48.396142Z",
     "iopub.status.busy": "2023-10-04T19:59:48.395758Z",
     "iopub.status.idle": "2023-10-04T19:59:48.453917Z",
     "shell.execute_reply": "2023-10-04T19:59:48.452676Z",
     "shell.execute_reply.started": "2023-10-04T19:59:48.396116Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df,test_size=0.2,shuffle=True)\n",
    "# val, test = train_test_split(test,test_size=0.5,shuffle=True)\n",
    "\n",
    "train = train.reset_index(drop=True)\n",
    "# val = val.reset_index(drop=True)\n",
    "test = test.reset_index(drop=True)\n",
    "\n",
    "train.shape,test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "324db13c",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:00:10.943644Z",
     "iopub.status.busy": "2023-10-04T20:00:10.943187Z",
     "iopub.status.idle": "2023-10-04T20:02:02.415046Z",
     "shell.execute_reply": "2023-10-04T20:02:02.413814Z",
     "shell.execute_reply.started": "2023-10-04T20:00:10.943610Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "from simple_nlp_library import embeddings, preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "stop_words = preprocessing.stop_words()\n",
    "vectors = embeddings.vectors()\n",
    "\n",
    "X_train = train['review'].tolist()\n",
    "X_train = [embeddings.tokens_vector(vectors, preprocessing.semantic_tokens(stop_words, x)) for x in X_train]\n",
    "y_train = train['sentiment'].tolist()\n",
    "\n",
    "X_test = test['review'].tolist()\n",
    "X_test = [embeddings.tokens_vector(vectors, preprocessing.semantic_tokens(stop_words, x)) for x in X_test]\n",
    "y_test = test['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99448a89",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model-0: MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "947a5331",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:02:07.766571Z",
     "iopub.status.busy": "2023-10-04T20:02:07.765381Z",
     "iopub.status.idle": "2023-10-04T20:02:25.175186Z",
     "shell.execute_reply": "2023-10-04T20:02:25.173569Z",
     "shell.execute_reply.started": "2023-10-04T20:02:07.766530Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=(25), early_stopping=True, n_iter_no_change=20).fit(X_train, y_train)\n",
    "\n",
    "\n",
    "clf.best_validation_score_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "484eb18c",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model-1: Naive Bayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1529e38b",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:02:29.930412Z",
     "iopub.status.busy": "2023-10-04T20:02:29.929912Z",
     "iopub.status.idle": "2023-10-04T20:02:29.981006Z",
     "shell.execute_reply": "2023-10-04T20:02:29.979583Z",
     "shell.execute_reply.started": "2023-10-04T20:02:29.930377Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train['review'].tolist()\n",
    "# X_train = [embeddings.tokens_vector(vectors, preprocessing.semantic_tokens(stop_words, x)) for x in X_train]\n",
    "y_train = train['sentiment'].tolist()\n",
    "\n",
    "X_test = test['review'].tolist()\n",
    "# X_test = [embeddings.tokens_vector(vectors, preprocessing.semantic_tokens(stop_words, x)) for x in X_test]\n",
    "y_test = test['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83be23e7",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:02:37.185931Z",
     "iopub.status.busy": "2023-10-04T20:02:37.185542Z",
     "iopub.status.idle": "2023-10-04T20:02:42.496686Z",
     "shell.execute_reply": "2023-10-04T20:02:42.495417Z",
     "shell.execute_reply.started": "2023-10-04T20:02:37.185899Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "nbpl = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer()),\n",
    "    ('naive_bayes', MultinomialNB())\n",
    "])\n",
    "\n",
    "nbpl.fit(X_train, y_train)\n",
    "y_pred = nbpl.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f104912",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "### Model-1: Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff51c13",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:02:48.226779Z",
     "iopub.status.busy": "2023-10-04T20:02:48.225976Z",
     "iopub.status.idle": "2023-10-04T20:02:48.242348Z",
     "shell.execute_reply": "2023-10-04T20:02:48.240720Z",
     "shell.execute_reply.started": "2023-10-04T20:02:48.226728Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train['review'].tolist()\n",
    "# X_train = [embeddings.tokens_vector(vectors, preprocessing.semantic_tokens(stop_words, x)) for x in X_train]\n",
    "y_train = train['sentiment'].tolist()\n",
    "\n",
    "X_test = test['review'].tolist()\n",
    "# X_test = [embeddings.tokens_vector(vectors, preprocessing.semantic_tokens(stop_words, x)) for x in X_test]\n",
    "y_test = test['sentiment'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94768222",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2023-10-04T20:02:51.300545Z",
     "iopub.status.busy": "2023-10-04T20:02:51.300195Z",
     "iopub.status.idle": "2023-10-04T20:04:43.148066Z",
     "shell.execute_reply": "2023-10-04T20:04:43.146736Z",
     "shell.execute_reply.started": "2023-10-04T20:02:51.300517Z"
    },
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "rfpl = Pipeline([\n",
    "    ('count_vectorizer', CountVectorizer()),\n",
    "    ('random_classifier', RandomForestClassifier(n_estimators=50, criterion='entropy'))\n",
    "])\n",
    "\n",
    "rfpl.fit(X_train, y_train)\n",
    "\n",
    "y_pred = rfpl.predict(X_test)\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec2356ad",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "source": [
    "# Conclusion:\n",
    "- MLP showed worde accuracy: 78% (preprocessing-v1), 76% (preprocessing-v2)\n",
    "- Random Forest and Naive Bayes showed the same accuracy: 86% (pre-processing-v1), 84%-85% (pre-processing-V2)\n",
    "- text preprocessing using v1: 67 sec\n",
    "- text pre-processing using v2 [spacy]: 1237.54 sec\n",
    "- spacy preprocessing resulted in less accurate classification then alernative pre-processing-v1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b799c318",
   "metadata": {
    "papermill": {
     "duration": null,
     "end_time": null,
     "exception": null,
     "start_time": null,
     "status": "pending"
    },
    "tags": []
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 2341.643738,
   "end_time": "2023-10-04T20:45:16.414859",
   "environment_variables": {},
   "exception": true,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2023-10-04T20:06:14.771121",
   "version": "2.4.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
